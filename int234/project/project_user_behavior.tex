% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Mobile Device Usage and User Behavior Classification},
  pdfauthor={Rohith Reddy},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Mobile Device Usage and User Behavior Classification}
\author{Rohith Reddy}
\date{2024-11-07}

\begin{document}
\maketitle

\subsection{Introduction:}\label{introduction}

In this project, we explore a Mobile Device Usage and User Behavior
Dataset to predict user behavior classes using multiple machine learning
models. We implement four different classification models: Random
Forest, K-Nearest Neighbors (KNN), and Support Vector Machine (SVM) and
Naive Bayes followed by performance evaluation and comparison.

\section{Load necessary libraries}\label{load-necessary-libraries}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(randomForest)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## randomForest 4.7-1.2
\end{verbatim}

\begin{verbatim}
## Type rfNews() to see new features/changes/bug fixes.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: ggplot2
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'ggplot2'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:randomForest':
## 
##     margin
\end{verbatim}

\begin{verbatim}
## Loading required package: lattice
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(class)}
\FunctionTok{library}\NormalTok{(e1071)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(reshape2)}
\FunctionTok{library}\NormalTok{(gmodels)}
\FunctionTok{library}\NormalTok{(caTools)}
\end{Highlighting}
\end{Shaded}

\subsection{1. Data Loading and
Preprocessing}\label{data-loading-and-preprocessing}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load the dataset}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"C:/Users/Dell/Desktop/int234/project/user\_behavior\_dataset.csv"}\NormalTok{)}
\FunctionTok{colnames}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "User.ID"                    "Device.Model"              
##  [3] "Operating.System"           "App.Usage.Time..min.day."  
##  [5] "Screen.On.Time..hours.day." "Battery.Drain..mAh.day."   
##  [7] "Number.of.Apps.Installed"   "Data.Usage..MB.day."       
##  [9] "Age"                        "Gender"                    
## [11] "User.Behavior.Class"
\end{verbatim}

Loading Dataset of User Behavior to perform predictive analysis and see
the result of different classifications models to find that which model
is giving high accuracy.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Ensure \textquotesingle{}User.Behavior.Class\textquotesingle{} is a factor}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{User.Behavior.Class }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{User.Behavior.Class)}
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ data[}\FunctionTok{sapply}\NormalTok{(data, is.atomic)]}
\CommentTok{\#Key Features/Structure of the data}
\FunctionTok{str}\NormalTok{(data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    700 obs. of  11 variables:
##  $ User.ID                   : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Device.Model              : chr  "Google Pixel 5" "OnePlus 9" "Xiaomi Mi 11" "Google Pixel 5" ...
##  $ Operating.System          : chr  "Android" "Android" "Android" "Android" ...
##  $ App.Usage.Time..min.day.  : int  393 268 154 239 187 99 350 543 340 424 ...
##  $ Screen.On.Time..hours.day.: num  6.4 4.7 4 4.8 4.3 2 7.3 11.4 7.7 6.6 ...
##  $ Battery.Drain..mAh.day.   : int  1872 1331 761 1676 1367 940 1802 2956 2138 1957 ...
##  $ Number.of.Apps.Installed  : int  67 42 32 56 58 35 66 82 75 75 ...
##  $ Data.Usage..MB.day.       : int  1122 944 322 871 988 564 1054 1702 1053 1301 ...
##  $ Age                       : int  40 47 42 20 31 31 21 31 42 42 ...
##  $ Gender                    : chr  "Male" "Female" "Male" "Male" ...
##  $ User.Behavior.Class       : Factor w/ 5 levels "1","2","3","4",..: 4 3 2 3 3 2 4 5 4 4 ...
\end{verbatim}

Split Dataset into Training and Testing Sets

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{) }
\NormalTok{train\_indices }\OtherTok{\textless{}{-}} \FunctionTok{createDataPartition}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{User.Behavior.Class, }\AttributeTok{p =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{list =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{trainData }\OtherTok{\textless{}{-}}\NormalTok{ data[train\_indices, ]}
\NormalTok{testData }\OtherTok{\textless{}{-}}\NormalTok{ data[}\SpecialCharTok{{-}}\NormalTok{train\_indices, ]}
\end{Highlighting}
\end{Shaded}

\subsection{2. Model Training and
Evaluation}\label{model-training-and-evaluation}

2.1 Random Forest Model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rf\_model }\OtherTok{\textless{}{-}} \FunctionTok{randomForest}\NormalTok{(User.Behavior.Class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ trainData, }\AttributeTok{ntree =} \DecValTok{500}\NormalTok{, }\AttributeTok{mtry =} \DecValTok{3}\NormalTok{, }\AttributeTok{importance =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{print}\NormalTok{(rf\_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
##  randomForest(formula = User.Behavior.Class ~ ., data = trainData,      ntree = 500, mtry = 3, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 0%
## Confusion matrix:
##    1   2   3  4  5 class.error
## 1 96   0   0  0  0           0
## 2  0 103   0  0  0           0
## 3  0   0 101  0  0           0
## 4  0   0   0 98  0           0
## 5  0   0   0  0 96           0
\end{verbatim}

2.1.1 Analysis of Accuracy of KNN model

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Predict and evaluate}
\NormalTok{predictions\_rf }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(rf\_model, }\AttributeTok{newdata =}\NormalTok{ testData)}
\NormalTok{conf\_matrix\_rf }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(testData}\SpecialCharTok{$}\NormalTok{User.Behavior.Class, predictions\_rf)}
\NormalTok{accuracy\_rf }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(conf\_matrix\_rf)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(conf\_matrix\_rf)}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Random Forest Accuracy:"}\NormalTok{, accuracy\_rf }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\StringTok{"\%}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Random Forest Accuracy: 100 %
\end{verbatim}

2.1.2 Variable Importance Plot

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{varImpPlot}\NormalTok{(rf\_model, }\AttributeTok{main =} \StringTok{"Variable Importance for Random Forest"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{project_user_behavior_files/figure-latex/unnamed-chunk-7-1.pdf}

2.2 K-Nearest Neighbors (KNN) Model

2.2.1 Preprocess: Normalize Features and Add Noise

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{normalize }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) \{ (x }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(x)) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{max}\NormalTok{(x) }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(x)) \}}
\NormalTok{numeric\_columns }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(data, is.numeric)}
\NormalTok{data\_n }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(}\FunctionTok{lapply}\NormalTok{(data[, numeric\_columns], normalize))}
\NormalTok{data\_n}\SpecialCharTok{$}\NormalTok{User.Behavior.Class }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{User.Behavior.Class}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{noise }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\AttributeTok{n =} \FunctionTok{nrow}\NormalTok{(data\_n) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{ncol}\NormalTok{(data\_n) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{), }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.1}\NormalTok{), }\AttributeTok{nrow =} \FunctionTok{nrow}\NormalTok{(data\_n))}
\NormalTok{data\_n[, }\SpecialCharTok{{-}}\FunctionTok{ncol}\NormalTok{(data\_n)] }\OtherTok{\textless{}{-}}\NormalTok{ data\_n[, }\SpecialCharTok{{-}}\FunctionTok{ncol}\NormalTok{(data\_n)] }\SpecialCharTok{+}\NormalTok{ noise}
\CommentTok{\# Summary of data with noise}
\FunctionTok{summary}\NormalTok{(data\_n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     User.ID        App.Usage.Time..min.day. Screen.On.Time..hours.day.
##  Min.   :-0.1723   Min.   :-0.1888          Min.   :-0.1799           
##  1st Qu.: 0.2444   1st Qu.: 0.1555          1st Qu.: 0.1496           
##  Median : 0.5116   Median : 0.3679          Median : 0.3671           
##  Mean   : 0.4997   Mean   : 0.4276          Mean   : 0.3923           
##  3rd Qu.: 0.7452   3rd Qu.: 0.7186          3rd Qu.: 0.5852           
##  Max.   : 1.2401   Max.   : 1.2058          Max.   : 1.1595           
##  Battery.Drain..mAh.day. Number.of.Apps.Installed Data.Usage..MB.day.
##  Min.   :-0.1920         Min.   :-0.2230          Min.   :-0.1943    
##  1st Qu.: 0.1803         1st Qu.: 0.1781          1st Qu.: 0.1138    
##  Median : 0.4427         Median : 0.4438          Median : 0.2971    
##  Mean   : 0.4513         Mean   : 0.4575          Mean   : 0.3441    
##  3rd Qu.: 0.7172         3rd Qu.: 0.7089          3rd Qu.: 0.5407    
##  Max.   : 1.1517         Max.   : 1.1525          Max.   : 1.0995    
##       Age          User.Behavior.Class
##  Min.   :-0.2245   1:136              
##  1st Qu.: 0.2444   2:146              
##  Median : 0.4875   3:143              
##  Mean   : 0.4980   4:139              
##  3rd Qu.: 0.7485   5:136              
##  Max.   : 1.1850
\end{verbatim}

2.2.2 Train-Test Split and KNN Model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_index }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(data\_n), }\FloatTok{0.7} \SpecialCharTok{*} \FunctionTok{nrow}\NormalTok{(data\_n))}
\NormalTok{data\_train }\OtherTok{\textless{}{-}}\NormalTok{ data\_n[train\_index, ]}
\NormalTok{data\_test }\OtherTok{\textless{}{-}}\NormalTok{ data\_n[}\SpecialCharTok{{-}}\NormalTok{train\_index, ]}
\NormalTok{train\_labels }\OtherTok{\textless{}{-}}\NormalTok{ data\_n}\SpecialCharTok{$}\NormalTok{User.Behavior.Class[train\_index]}
\NormalTok{test\_labels }\OtherTok{\textless{}{-}}\NormalTok{ data\_n}\SpecialCharTok{$}\NormalTok{User.Behavior.Class[}\SpecialCharTok{{-}}\NormalTok{train\_index]}

\NormalTok{k }\OtherTok{\textless{}{-}} \DecValTok{50}  \CommentTok{\# Adjust as needed}
\NormalTok{test\_pred\_knn }\OtherTok{\textless{}{-}} \FunctionTok{knn}\NormalTok{(}\AttributeTok{train =}\NormalTok{ data\_train[, }\SpecialCharTok{{-}}\FunctionTok{ncol}\NormalTok{(data\_train)], }\AttributeTok{test =}\NormalTok{ data\_test[, }\SpecialCharTok{{-}}\FunctionTok{ncol}\NormalTok{(data\_test)], }\AttributeTok{cl =}\NormalTok{ train\_labels, }\AttributeTok{k =}\NormalTok{ k)}
\NormalTok{conf\_matrix\_knn }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(test\_labels, test\_pred\_knn)}
\NormalTok{conf\_matrix\_knn}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            test_pred_knn
## test_labels  1  2  3  4  5
##           1 40  2  0  0  0
##           2  4 38  1  0  0
##           3  0  2 42  0  0
##           4  0  0  3 40  0
##           5  0  0  0  1 38
\end{verbatim}

2.2.3 Analysis of Accuracy of KNN model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accuracy\_knn }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(test\_pred\_knn }\SpecialCharTok{==}\NormalTok{ test\_labels) }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(test\_labels)}
\FunctionTok{cat}\NormalTok{(}\StringTok{"KNN Accuracy:"}\NormalTok{, }\FunctionTok{round}\NormalTok{(accuracy\_knn }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{2}\NormalTok{), }\StringTok{"\%}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## KNN Accuracy: 93.84 %
\end{verbatim}

2.3 Naive Bayes Model with Feature Reduction

2.3.1 Features and Normalization

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_reduced }\OtherTok{\textless{}{-}}\NormalTok{ data\_n[, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{]  }\CommentTok{\# Example: Adjust based on feature selection}
\NormalTok{split }\OtherTok{\textless{}{-}} \FunctionTok{sample.split}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{User.Behavior.Class, }\AttributeTok{SplitRatio =} \FloatTok{0.7}\NormalTok{)}
\NormalTok{train\_set }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(data\_reduced, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(data\_reduced, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{train\_labels }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{User.Behavior.Class, split }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{test\_labels }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{User.Behavior.Class, split }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

2.3.2 Train and Evaluate Naive Bayes Model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb\_model }\OtherTok{\textless{}{-}} \FunctionTok{naiveBayes}\NormalTok{(train\_set, train\_labels)}
\NormalTok{pred\_labels\_nb }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(nb\_model, test\_set)}
\NormalTok{conf\_matrix\_nb }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(test\_labels, pred\_labels\_nb)}
\NormalTok{conf\_matrix\_nb}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            pred_labels_nb
## test_labels  1  2  3  4  5
##           1 26 15  0  0  0
##           2 15 19 10  0  0
##           3  1  7 31  4  0
##           4  0  0  7 27  8
##           5  0  0  0 10 31
\end{verbatim}

2.3.3 Analysis of Accuracy of Naive Bayes Model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accuracy\_nb }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(conf\_matrix\_nb)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(conf\_matrix\_nb)}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Naive Bayes Accuracy with reduced features:"}\NormalTok{, }\FunctionTok{round}\NormalTok{(accuracy\_nb }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{2}\NormalTok{), }\StringTok{"\%}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Naive Bayes Accuracy with reduced features: 63.51 %
\end{verbatim}

2.4 Support Vector Machine (SVM)

2.4.1 Train and Evaluate SVM Model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(User.Behavior.Class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ trainData, }\AttributeTok{kernel =} \StringTok{"radial"}\NormalTok{, }\AttributeTok{cost =} \FloatTok{0.09}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{predictions\_svm }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(svm\_model, }\AttributeTok{newdata =}\NormalTok{ testData)}
\NormalTok{conf\_matrix\_svm }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(testData}\SpecialCharTok{$}\NormalTok{User.Behavior.Class, predictions\_svm)}
\NormalTok{conf\_matrix\_svm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    predictions_svm
##      1  2  3  4  5
##   1 39  1  0  0  0
##   2  0 43  0  0  0
##   3  0  0 42  0  0
##   4  0  0  0 41  0
##   5  0  0  0  0 40
\end{verbatim}

2.4.2 Analysis of Accuracy of SVM

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accuracy\_svm }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(conf\_matrix\_svm)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(conf\_matrix\_svm)}
\FunctionTok{cat}\NormalTok{(}\StringTok{"SVM Accuracy:"}\NormalTok{, accuracy\_svm }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\StringTok{"\%}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## SVM Accuracy: 99.51456 %
\end{verbatim}

3.Visualizations of Confusion Matrices

3.1 Random Forest Confusion Matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf\_matrix\_rf\_df }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(conf\_matrix\_rf)}
\FunctionTok{colnames}\NormalTok{(conf\_matrix\_rf\_df) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Actual"}\NormalTok{, }\StringTok{"Predicted"}\NormalTok{, }\StringTok{"Count"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ conf\_matrix\_rf\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Actual, }\AttributeTok{y =}\NormalTok{ Predicted)) }\SpecialCharTok{+}
  \FunctionTok{geom\_tile}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ Count), }\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_gradient}\NormalTok{(}\AttributeTok{low =} \StringTok{"white"}\NormalTok{, }\AttributeTok{high =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ Count), }\AttributeTok{vjust =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Confusion Matrix for Random Forest"}\NormalTok{, }\AttributeTok{x =} \StringTok{"Actual"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Predicted"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{project_user_behavior_files/figure-latex/unnamed-chunk-16-1.pdf}

3.2 KNN Confusion Matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf\_matrix\_knn\_df }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(conf\_matrix\_knn)}
\FunctionTok{colnames}\NormalTok{(conf\_matrix\_knn\_df) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Actual"}\NormalTok{, }\StringTok{"Predicted"}\NormalTok{, }\StringTok{"Count"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ conf\_matrix\_knn\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Actual, }\AttributeTok{y =}\NormalTok{ Predicted)) }\SpecialCharTok{+}
  \FunctionTok{geom\_tile}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ Count), }\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_gradient}\NormalTok{(}\AttributeTok{low =} \StringTok{"white"}\NormalTok{, }\AttributeTok{high =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ Count), }\AttributeTok{vjust =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Confusion Matrix for KNN"}\NormalTok{, }\AttributeTok{x =} \StringTok{"Actual"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Predicted"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{project_user_behavior_files/figure-latex/unnamed-chunk-17-1.pdf}

3.3 Naive Bayes Confusion Matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf\_matrix\_nb\_df }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(conf\_matrix\_nb)}
\FunctionTok{colnames}\NormalTok{(conf\_matrix\_nb\_df) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Actual"}\NormalTok{, }\StringTok{"Predicted"}\NormalTok{, }\StringTok{"Count"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ conf\_matrix\_nb\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Actual, }\AttributeTok{y =}\NormalTok{ Predicted)) }\SpecialCharTok{+}
  \FunctionTok{geom\_tile}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ Count), }\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_gradient}\NormalTok{(}\AttributeTok{low =} \StringTok{"white"}\NormalTok{, }\AttributeTok{high =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ Count), }\AttributeTok{vjust =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Confusion Matrix for Naive Bayes"}\NormalTok{, }\AttributeTok{x =} \StringTok{"Actual"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Predicted"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{project_user_behavior_files/figure-latex/unnamed-chunk-18-1.pdf}

3.4 SVM Confusion Matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf\_matrix\_svm\_df }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(conf\_matrix\_svm)}
\FunctionTok{colnames}\NormalTok{(conf\_matrix\_svm\_df) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Actual"}\NormalTok{, }\StringTok{"Predicted"}\NormalTok{, }\StringTok{"Count"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ conf\_matrix\_svm\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Actual, }\AttributeTok{y =}\NormalTok{ Predicted)) }\SpecialCharTok{+}
  \FunctionTok{geom\_tile}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ Count), }\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_gradient}\NormalTok{(}\AttributeTok{low =} \StringTok{"white"}\NormalTok{, }\AttributeTok{high =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ Count), }\AttributeTok{vjust =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Confusion Matrix for SVM"}\NormalTok{, }\AttributeTok{x =} \StringTok{"Actual"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Predicted"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{project_user_behavior_files/figure-latex/unnamed-chunk-19-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Model Comparison

  4.1 Accuracy Comparison of Models
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{accuracies }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Model =} \FunctionTok{c}\NormalTok{(}\StringTok{"KNN"}\NormalTok{, }\StringTok{"Naive Bayes"}\NormalTok{, }\StringTok{"Random Forest"}\NormalTok{, }\StringTok{"SVM"}\NormalTok{),}
  \AttributeTok{Accuracy =} \FunctionTok{c}\NormalTok{(accuracy\_knn, accuracy\_nb, accuracy\_rf, accuracy\_svm)}
\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ accuracies, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Model, }\AttributeTok{y =}\NormalTok{ Accuracy, }\AttributeTok{fill =}\NormalTok{ Model)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =} \FunctionTok{paste0}\NormalTok{(}\FunctionTok{round}\NormalTok{(Accuracy }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\DecValTok{2}\NormalTok{), }\StringTok{"\%"}\NormalTok{)), }\AttributeTok{vjust =} \SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{, }\AttributeTok{size =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{labels =}\NormalTok{ scales}\SpecialCharTok{::}\FunctionTok{percent\_format}\NormalTok{(}\AttributeTok{accuracy =} \DecValTok{1}\NormalTok{), }\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Model Accuracy Comparison"}\NormalTok{, }\AttributeTok{x =} \StringTok{"Model"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Accuracy"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{project_user_behavior_files/figure-latex/unnamed-chunk-20-1.pdf}

\end{document}
